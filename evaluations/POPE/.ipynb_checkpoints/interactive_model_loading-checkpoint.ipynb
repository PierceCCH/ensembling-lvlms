{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6fd342-63cc-42bd-b14f-398402943b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:01.540836Z",
     "iopub.status.busy": "2024-11-18T04:07:01.540836Z",
     "iopub.status.idle": "2024-11-18T04:07:04.749403Z",
     "shell.execute_reply": "2024-11-18T04:07:04.749403Z",
     "shell.execute_reply.started": "2024-11-18T04:07:01.540836Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "import requests\n",
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660d73c3-902d-4278-b655-1507aaf21b74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:04.750408Z",
     "iopub.status.busy": "2024-11-18T04:07:04.749403Z",
     "iopub.status.idle": "2024-11-18T04:07:04.752091Z",
     "shell.execute_reply": "2024-11-18T04:07:04.752091Z",
     "shell.execute_reply.started": "2024-11-18T04:07:04.750408Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.curdir, \"model_responses.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e40994c-cce3-473d-bb05-8e14372a207e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:04.753097Z",
     "iopub.status.busy": "2024-11-18T04:07:04.752091Z",
     "iopub.status.idle": "2024-11-18T04:07:04.757592Z",
     "shell.execute_reply": "2024-11-18T04:07:04.757592Z",
     "shell.execute_reply.started": "2024-11-18T04:07:04.753097Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a79ce6e-788e-4ad3-811f-7f2cfe7968e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:04.758597Z",
     "iopub.status.busy": "2024-11-18T04:07:04.757592Z",
     "iopub.status.idle": "2024-11-18T04:07:04.763409Z",
     "shell.execute_reply": "2024-11-18T04:07:04.763409Z",
     "shell.execute_reply.started": "2024-11-18T04:07:04.757592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb008f2-d783-4e01-8741-78f7bca75f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:04.764415Z",
     "iopub.status.busy": "2024-11-18T04:07:04.763409Z",
     "iopub.status.idle": "2024-11-18T04:07:05.336789Z",
     "shell.execute_reply": "2024-11-18T04:07:05.336789Z",
     "shell.execute_reply.started": "2024-11-18T04:07:04.764415Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processor = LlavaNextProcessor.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4cf6d90-011a-4909-998e-6bab1f7d1678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:05.338792Z",
     "iopub.status.busy": "2024-11-18T04:07:05.337792Z",
     "iopub.status.idle": "2024-11-18T04:07:10.677512Z",
     "shell.execute_reply": "2024-11-18T04:07:10.677512Z",
     "shell.execute_reply.started": "2024-11-18T04:07:05.337792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95273e86d96a4a7ea70d17cfc2e44e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlavaNextForConditionalGeneration(\n",
       "  (vision_tower): CLIPVisionModel(\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(577, 1024)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x CLIPEncoderLayer(\n",
       "            (self_attn): CLIPSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): LlavaNextMultiModalProjector(\n",
       "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (act): GELUActivation()\n",
       "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       "  (language_model): MistralForCausalLM(\n",
       "    (model): MistralModel(\n",
       "      (embed_tokens): Embedding(32064, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x MistralDecoderLayer(\n",
       "          (self_attn): MistralSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): MistralRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): MistralMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LlavaNextForConditionalGeneration.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\", torch_dtype=torch.float16, low_cpu_mem_usage=True, device_map=device) \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9d5ebc-a93a-43af-b341-b866ad5a2eca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:10.677512Z",
     "iopub.status.busy": "2024-11-18T04:07:10.677512Z",
     "iopub.status.idle": "2024-11-18T04:07:10.685341Z",
     "shell.execute_reply": "2024-11-18T04:07:10.680829Z",
     "shell.execute_reply.started": "2024-11-18T04:07:10.677512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n",
      "Memory Usage:\n",
      "Allocated: 14.1 GB\n",
      "Cached:    14.2 GB\n"
     ]
    }
   ],
   "source": [
    "#check where the tensors are allocated\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f6037d-d617-490b-95dd-12304946c496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:10.686341Z",
     "iopub.status.busy": "2024-11-18T04:07:10.686341Z",
     "iopub.status.idle": "2024-11-18T04:07:10.693823Z",
     "shell.execute_reply": "2024-11-18T04:07:10.693823Z",
     "shell.execute_reply.started": "2024-11-18T04:07:10.686341Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is to load pope\n",
    "# dataset = load_dataset(\"lmms-lab/POPE\", \"default\")\n",
    "# dataset = dataset['test'].filter(lambda x: x['category'] == 'adversarial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9808cbe-81fe-4c7b-a122-0a11ec95fd53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:10.694827Z",
     "iopub.status.busy": "2024-11-18T04:07:10.694827Z",
     "iopub.status.idle": "2024-11-18T04:07:13.407037Z",
     "shell.execute_reply": "2024-11-18T04:07:13.407037Z",
     "shell.execute_reply.started": "2024-11-18T04:07:10.694827Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is to load hallusion bench\n",
    "dataset = load_dataset(\"lmms-lab/HallusionBench\", \"default\")\n",
    "dataset = dataset['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "165d4719-7940-4b54-9037-ebcd5945c9c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:13.407037Z",
     "iopub.status.busy": "2024-11-18T04:07:13.407037Z",
     "iopub.status.idle": "2024-11-18T04:07:13.410469Z",
     "shell.execute_reply": "2024-11-18T04:07:13.410469Z",
     "shell.execute_reply.started": "2024-11-18T04:07:13.407037Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_response(question, image):\n",
    "    \"\"\" Prompt model with question regarding image and generate response.\n",
    "\n",
    "    Args:\n",
    "        question (str): question regarding the image content\n",
    "        image_path (str): PIL image object\n",
    "    \n",
    "    Returns:\n",
    "        response (str): model's response to the question\n",
    "    \"\"\"\n",
    "    inputs = processor(images=image, text=question, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a15ec993-56f2-41f6-b37c-92929d66e2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:13.411473Z",
     "iopub.status.busy": "2024-11-18T04:07:13.410469Z",
     "iopub.status.idle": "2024-11-18T04:07:13.415648Z",
     "shell.execute_reply": "2024-11-18T04:07:13.415648Z",
     "shell.execute_reply.started": "2024-11-18T04:07:13.411473Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_response_new(question,image):\n",
    "    conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": question},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    inputs = processor(image, prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "    _, length_inputs = inputs[\"input_ids\"].shape\n",
    "    # print(\"length of inputs: \", length_inputs)\n",
    "    # autoregressively complete prompt\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "    output = output[:, length_inputs:]\n",
    "    \n",
    "    return processor.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d8787c-e897-4db2-b275-ef6df14e7f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:13.415648Z",
     "iopub.status.busy": "2024-11-18T04:07:13.415648Z",
     "iopub.status.idle": "2024-11-18T04:07:13.420839Z",
     "shell.execute_reply": "2024-11-18T04:07:13.420839Z",
     "shell.execute_reply.started": "2024-11-18T04:07:13.415648Z"
    }
   },
   "outputs": [],
   "source": [
    "#access the RAM tags\n",
    "def tags_to_dict(filepath):\n",
    "    filepath = filepath\n",
    "    ram_data = {}\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip().rstrip(\",\")\n",
    "    \n",
    "            data_entry = json.loads(line)\n",
    "    \n",
    "            ram_data.update(data_entry)\n",
    "    return ram_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b17a856e-3f50-462f-94d9-a797caa89e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:13.421842Z",
     "iopub.status.busy": "2024-11-18T04:07:13.420839Z",
     "iopub.status.idle": "2024-11-18T04:07:13.425217Z",
     "shell.execute_reply": "2024-11-18T04:07:13.425217Z",
     "shell.execute_reply.started": "2024-11-18T04:07:13.421842Z"
    }
   },
   "outputs": [],
   "source": [
    "pope_tag_path =  \"../../models/recognize-anything/pope_tags.json\"\n",
    "hallusion_tag_path = \"../../models/recognize-anything/hallusionBench_tags.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f76e9c92-8a1e-48df-b0a8-27756efe7ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:08:05.920339Z",
     "iopub.status.busy": "2024-11-18T04:08:05.920339Z",
     "iopub.status.idle": "2024-11-18T04:08:05.922854Z",
     "shell.execute_reply": "2024-11-18T04:08:05.922854Z",
     "shell.execute_reply.started": "2024-11-18T04:08:05.920339Z"
    }
   },
   "outputs": [],
   "source": [
    "ram_data = tags_to_dict(hallusion_tag_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af247376-024c-4fab-b3d4-10c37ae12108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:13.431968Z",
     "iopub.status.busy": "2024-11-18T04:07:13.430965Z",
     "iopub.status.idle": "2024-11-18T04:07:13.434607Z",
     "shell.execute_reply": "2024-11-18T04:07:13.434607Z",
     "shell.execute_reply.started": "2024-11-18T04:07:13.431968Z"
    }
   },
   "outputs": [],
   "source": [
    "def obtain_attributes(img_src):\n",
    "    \"\"\"\n",
    "    Returns the attributes identified by RAM.\n",
    "    \"\"\"\n",
    "    injection = \"This image has these attributes: \"\n",
    "    image_attrs = ram_data[img_src]\n",
    "    image_attrs = image_attrs.replace('|',' ').split()\n",
    "    injection = \"This image has these attributes: \"\n",
    "    for i in range(len(image_attrs)):\n",
    "        if i == len(image_attrs) - 2:\n",
    "            injection = injection + image_attrs[i]+\", and \"\n",
    "        elif i == len(image_attrs) - 1:\n",
    "            injection = injection + image_attrs[i] +\". \"\n",
    "        else:\n",
    "            injection = injection + image_attrs[i] + \", \"\n",
    "    return injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97cebc5f-6d24-44b5-a649-694e01d74ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:07:13.434607Z",
     "iopub.status.busy": "2024-11-18T04:07:13.434607Z",
     "iopub.status.idle": "2024-11-18T04:07:13.439697Z",
     "shell.execute_reply": "2024-11-18T04:07:13.439697Z",
     "shell.execute_reply.started": "2024-11-18T04:07:13.434607Z"
    }
   },
   "outputs": [],
   "source": [
    "def inject_info(img_src, question):\n",
    "    \"\"\"\n",
    "    Injects prompt with any needed information. So given question, it will tell the lvlm also what it contains.\n",
    "    Should fine-tune prompt later.\n",
    "    \"\"\"\n",
    "    image_attrs = ram_data[img_src]\n",
    "    image_attrs = image_attrs.replace('|',' ').split()\n",
    "    injection = obtain_attributes(img_src)\n",
    "    injection = injection + f\"Using this information answer the following question: {question}\"\n",
    "    return injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96bbf1fe-3e00-4285-9872-09a6826ee7a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:08:11.555417Z",
     "iopub.status.busy": "2024-11-18T04:08:11.555417Z",
     "iopub.status.idle": "2024-11-18T04:08:22.157118Z",
     "shell.execute_reply": "2024-11-18T04:08:22.157118Z",
     "shell.execute_reply.started": "2024-11-18T04:08:11.555417Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image has these attributes: graph, number, and individual. Using this information answer the following question: Is China, Hongkong SAR, the leading importing country of gold, silverware, and jewelry with the highest import value in 2018? : The image you've provided shows a bar chart comparing the import value of gold, silverware, and jewelry among several countries in 2018. According to the chart, China, Hong Kong SAR, is indeed the leading importer of these goods, with an import value of $10,000. This is significantly higher than the import values of other countries listed on the chart. \n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for idx in range(len(dataset)):\n",
    "    question = dataset['question'][idx]\n",
    "    image = dataset['image'][idx]\n",
    "    img_source = dataset['filename'][idx] #this is for hallusion bench\n",
    "    # img_source = dataset['image_source'][idx]#this is for pope\n",
    "    prompt = inject_info(img_source, question)\n",
    "    response = generate_response_new(question, image)\n",
    "    responses.append({\n",
    "        'question': question,\n",
    "        'response': response\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697cff7b-1e57-4ad6-8c7c-466d3c5b7467",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-18T04:07:21.052298Z",
     "iopub.status.idle": "2024-11-18T04:07:21.052298Z",
     "shell.execute_reply": "2024-11-18T04:07:21.052298Z",
     "shell.execute_reply.started": "2024-11-18T04:07:21.052298Z"
    }
   },
   "outputs": [],
   "source": [
    "llava_pope_output_path = os.path.join(os.curdir, \"internvl_pope_responses.json\")\n",
    "llava_hallusion_output_path =  os.path.join(os.curdir, \"internvl_hallusion_responses.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8bf184-deb0-4d7b-8b9f-49bf01cdf8e2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-18T04:07:21.053301Z",
     "iopub.status.idle": "2024-11-18T04:07:21.053301Z",
     "shell.execute_reply": "2024-11-18T04:07:21.053301Z",
     "shell.execute_reply.started": "2024-11-18T04:07:21.053301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write responses to file\n",
    "output_path = llava_pope_output_path\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(responses, f, indent=4)\n",
    "\n",
    "print(f\"LLaVa's responses have been saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
